{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r ./requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非配对数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "from ldct.utils import *\n",
    "from ldct.data import *\n",
    "from ldct.loss import *\n",
    "from ldct.net.generator import *\n",
    "from ldct.net.discriminator import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_path = \"../../LDCT_SLL_1000_200/train/fd/\"\n",
    "ld_path = \"../../LDCT_SLL_1000_200/train/qd/\"\n",
    "train_set = LDCT_CycleGan_Dataset(fd_path,ld_path,crop_size=(256,256))\n",
    "\n",
    "fd_path = \"../../LDCT_SLL_1000_200/test/fd/\"\n",
    "ld_path = \"../../LDCT_SLL_1000_200/test/qd/\"\n",
    "test_set = LDCT_Dataset(fd_path,ld_path,crop_size=(512,512))\n",
    "\n",
    "len(train_set),len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1, 256, 256]), torch.Size([4, 1, 256, 256]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "num_workers = 4\n",
    "train_loader = DataLoader(train_set,batch_size,num_workers=num_workers)\n",
    "test_loader = DataLoader(test_set,1)\n",
    "\n",
    "img_ld,img_fd = next(iter(train_loader))\n",
    "img_fd.shape, img_ld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Path\n",
    "save_path = \"./model/temp\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "# Logger\n",
    "logger = logging.getLogger('logger')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers=[]\n",
    "fh = logging.FileHandler(os.path.join(save_path,'log.log'),\"w\")\n",
    "fh.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)        \n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model\n",
    "G_AB = Generator_Unet_SEECA().to(device)\n",
    "G_BA = Generator_Unet_SEECA().to(device)\n",
    "D_A = Discriminator_Patch().to(device)\n",
    "D_B = Discriminator_Patch().to(device)\n",
    "logger.info(f\"G_param_count:\\t{model_param_count(G_AB)/1024/1024:.3f} M\")\n",
    "logger.info(f\"D_param_count:\\t{model_param_count(D_A)/1024/1024:.3f} M\")\n",
    "\n",
    "# Optim\n",
    "lr_G = 1e-4\n",
    "lr_D = 2e-4\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    itertools.chain(G_AB.parameters(), G_BA.parameters()),\n",
    "    lr=lr_G,\n",
    "    betas=(0.5, 0.9),\n",
    ")\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    itertools.chain(D_A.parameters(), D_B.parameters()),\n",
    "    lr=lr_D,\n",
    "    betas=(0.9, 0.999),\n",
    ")\n",
    "\n",
    "# Lossess\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "# criterion_identity = L1_Perc_Loss(x,y).to(device)\n",
    "\n",
    "# Training Set\n",
    "epoches=1000\n",
    "patient = 5\n",
    "rmse_best = np.Inf\n",
    "psnr_best = 0\n",
    "id_lamb = 5\n",
    "gan_lamb = 10\n",
    "\n",
    "# optim-scheduler\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(epoches).step)\n",
    "lr_scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lr_lambda=LambdaLR(epoches).step)\n",
    "\n",
    "\n",
    "\n",
    "e_count=patient\n",
    "for e in range(epoches):\n",
    "    G_loss_list = []\n",
    "    D_A_loss_list = []\n",
    "    D_B_loss_list = []\n",
    "    for real_A, real_B in tqdm(train_loader):\n",
    "        real_A, real_B = real_A.to(device), real_B.to(device)\n",
    "        target_real = Variable(\n",
    "            torch.ones((real_A.shape[0], 1, 30, 30)), requires_grad=False\n",
    "            # torch.ones((real_A.shape[0], 1)), requires_grad=False\n",
    "        ).to(device)\n",
    "        target_fake = Variable(\n",
    "            torch.zeros((real_A.shape[0], 1, 30, 30)), requires_grad=False\n",
    "            # torch.zeros((real_A.shape[0], 1)), requires_grad=False\n",
    "        ).to(device)\n",
    "\n",
    "        # # Train G\n",
    "        G_AB.train(),G_BA.train()\n",
    "        D_A.eval(),D_B.eval()\n",
    "        fake_A = G_BA(real_B)\n",
    "        fake_B = G_AB(real_A)\n",
    "        fake_AB = G_AB(fake_A)\n",
    "        fake_BA = G_BA(fake_B)\n",
    "        # Identity loss\n",
    "        loss_identity_A = criterion_identity(fake_A, real_B)\n",
    "        loss_identity_B = criterion_identity(fake_B, real_A)\n",
    "        loss_identity = loss_identity_A+loss_identity_B\n",
    "        # GAN loss\n",
    "        loss_gan_A = criterion_GAN(D_A(fake_A),target_real)\n",
    "        loss_gan_B = criterion_GAN(D_B(fake_B),target_real)\n",
    "        loss_gan = loss_gan_A+loss_gan_B\n",
    "        # Cycle Loss\n",
    "        loss_cycle_A = criterion_cycle(fake_BA,real_A)\n",
    "        loss_cycle_B = criterion_cycle(fake_AB,real_B)\n",
    "        loss_cycle = loss_cycle_A+loss_cycle_B\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = id_lamb*loss_identity + gan_lamb*loss_gan + loss_cycle\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        G_loss_list.append(loss_G.item())\n",
    "\n",
    "        # # Train D\n",
    "        D_A.train(),D_B.train()\n",
    "        G_AB.eval(),G_BA.eval()\n",
    "        fake_A = G_BA(real_B)\n",
    "        fake_B = G_AB(real_A)\n",
    "        # D loss\n",
    "        loss_D_A = criterion_GAN(D_A(real_A),target_real)+criterion_GAN(D_A(fake_A),target_fake)\n",
    "        loss_D_B = criterion_GAN(D_B(real_B),target_real)+criterion_GAN(D_B(fake_B),target_fake)\n",
    "        loss_D = loss_D_A + loss_D_B\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        D_A_loss_list.append(loss_D_A.item())\n",
    "        D_B_loss_list.append(loss_D_B.item())\n",
    "\n",
    "    # Loss Mean\n",
    "    G_loss, D_A_loss, D_B_loss = (\n",
    "    np.mean(G_loss_list),\n",
    "    np.mean(D_A_loss_list),\n",
    "    np.mean(D_B_loss_list),\n",
    "    )\n",
    "    # Update learning rates\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D.step()\n",
    "\n",
    "    # Save models checkpoints\n",
    "    rmse_list = []\n",
    "    psnr_list = []\n",
    "    for img_ld,img_fd in tqdm(test_loader):\n",
    "        img_ld, img_fd = img_ld.to(device), img_fd.to(device)\n",
    "        img_ld = G_AB(img_ld).detach()\n",
    "        img_ld, img_fd = img_ld.cpu(), img_fd.cpu()\n",
    "        # rmse_list.append(rmse(img_ld*255,img_fd*255).item())\n",
    "        psnr_list.append(psnr(img_ld*255,img_fd*255).item())\n",
    "    # rmse_val = np.mean(rmse_list)\n",
    "    psnr_val = np.mean(psnr_list)\n",
    "\n",
    "    if psnr_val > psnr_best:\n",
    "        psnr_best = psnr_val\n",
    "        e_count = patient\n",
    "        torch.save(G_AB, os.path.join(save_path,'best_GAB.pth'))\n",
    "    torch.save(G_AB, os.path.join(save_path,'latest_GAB.pth'))\n",
    "\n",
    "\n",
    "    info = f\"{e}/{epoches}\\tG: {G_loss}\\tDA: {D_A_loss}\\tDB: {D_B_loss}\\tPSNR/Best: {psnr_val}/{psnr_best}\"\n",
    "    print(info)\n",
    "    logger.info(info)\n",
    "\n",
    "    e_count-=1\n",
    "    if e_count<1:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = torch.load(os.path.join(save_path,\"best_GAB.pth\"),map_location=device)\n",
    "model = model.eval()\n",
    "psnr_list = []\n",
    "ssim_list = []\n",
    "gmsd_list = []\n",
    "rmse_list = []\n",
    "for img_ld,img_fd in tqdm(test_loader):\n",
    "    img_ld, img_fd = img_ld.to(device), img_fd.to(device)\n",
    "    img_ld = model(img_ld).detach()\n",
    "\n",
    "    img_ld, img_fd = img_ld.cpu(), img_fd.cpu()\n",
    "    psnr_list.append(psnr(img_ld*255,img_fd*255).item())\n",
    "    ssim_list.append(ssim(img_ld*255,img_fd*255).item())\n",
    "    gmsd_list.append(gmsd(img_ld*255,img_fd*255).item())\n",
    "    rmse_list.append(rmse(img_ld*255,img_fd*255).item())\n",
    "print(f\"{np.mean(psnr_list):.3f}\\t{np.mean(ssim_list):.3f}\\t{np.mean(gmsd_list):.3f}\\t{np.mean(rmse_list):.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
