{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r ./requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配对数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "from ldct.utils import *\n",
    "from ldct.train import Trainer\n",
    "from ldct.data import *\n",
    "from ldct.loss import *\n",
    "from ldct.net.generator import *\n",
    "from ldct.net.red_cnn import *\n",
    "from ldct.net.discriminator import Discriminator_Patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_path = \"../../LDCT_SLL_1000_200/train/fd/\"\n",
    "ld_path = \"../../LDCT_SLL_1000_200/train/qd/\"\n",
    "train_set = LDCT_Dataset(fd_path,ld_path,crop_size=(256,256))\n",
    "\n",
    "fd_path = \"../../LDCT_SLL_1000_200/test/fd/\"\n",
    "ld_path = \"../../LDCT_SLL_1000_200/test/qd/\"\n",
    "test_set = LDCT_Dataset(fd_path,ld_path,crop_size=(512,512))\n",
    "\n",
    "len(train_set),len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_workers = 4\n",
    "train_loader = DataLoader(train_set,batch_size,num_workers=num_workers)\n",
    "test_loader = DataLoader(test_set,1)\n",
    "\n",
    "img_ld,img_fd = next(iter(train_loader))\n",
    "img_fd.shape, img_ld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Path\n",
    "save_path = \"./model/temp\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "# Logger\n",
    "logger = logging.getLogger('logger')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers=[]\n",
    "fh = logging.FileHandler(os.path.join(save_path,'log.log'),\"w\")\n",
    "fh.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)        \n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model\n",
    "model = Generator_Unet_SEECA().to(device)\n",
    "logger.info(f\"param_count:\\t{model_param_count(model)/1024/1024:.3f} M\")\n",
    "\n",
    "# Optim\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=3e-4)\n",
    "# Lossess\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training Set\n",
    "epoches=1000\n",
    "patient = 5\n",
    "rmse_best = np.Inf\n",
    "psnr_best = 0\n",
    "id_lamb = 5\n",
    "gan_lamb = 10\n",
    "\n",
    "# optim-scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=LambdaLR(epoches).step)\n",
    "\n",
    "\n",
    "e_count=patient\n",
    "for e in range(epoches):\n",
    "    loss_list = []\n",
    "    for ldct, ndct in tqdm(train_loader):\n",
    "        ldct, ndct = ldct.to(device), ndct.to(device)\n",
    "        # Train\n",
    "        pred = model(ldct)\n",
    "        loss = criterion(pred,ndct)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    " \n",
    "    # Loss Mean\n",
    "    loss = np.mean(loss_list)\n",
    "    # Update learning rates\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Save models checkpoints\n",
    "    rmse_list = []\n",
    "    psnr_list = []\n",
    "    for img_ld,img_fd in tqdm(test_loader):\n",
    "        img_ld, img_fd = img_ld.to(device), img_fd.to(device)\n",
    "        img_ld = model(img_ld).detach()\n",
    "        img_ld, img_fd = img_ld.cpu(), img_fd.cpu()\n",
    "        psnr_list.append(psnr(img_ld*255,img_fd*255).item())\n",
    "    psnr_val = np.mean(psnr_list)\n",
    "\n",
    "    if psnr_val > psnr_best:\n",
    "        psnr_best = psnr_val\n",
    "        e_count = patient\n",
    "        torch.save(model, os.path.join(save_path,'best_GAB.pth'))\n",
    "\n",
    "    info = f\"{e}/{epoches}\\tloss: {loss}\\tPSNR/Best: {psnr_val}/{psnr_best}\"\n",
    "    print(info)\n",
    "    logger.info(info)\n",
    "\n",
    "    e_count-=1\n",
    "    if e_count<1:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
